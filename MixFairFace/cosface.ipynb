{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Caucasian\n",
    "# 1 - Indian\n",
    "# 2 - Asian\n",
    "# 3 - Asian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CosFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/.venv/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/.venv/lib/python3.11/site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/.venv/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/.venv/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/.venv/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/.venv/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/.venv/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/.venv/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/.venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "from cosface import CosFaceLoss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from directory structure using ImageFolder\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data = ImageFolder(root='/Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/resources/data/train/', transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "\n",
    "# Initialize ResNet34 model\n",
    "model = models.resnet34(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "# Remove the final classification layer\n",
    "model = nn.Sequential(*list(model.children())[:-1])  # Remove the last fully connected layer\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CosFace loss function\n",
    "criterion = CosFaceLoss(in_features=num_ftrs, out_features=4, s=64.0, m=0.35)\n",
    "\n",
    "# Initialize SGD optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Learning rate scheduler with step decay\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[8, 18, 30, 34], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({'Loss': running_loss / ((pbar.n) * images.size(0))})\n",
    "        \n",
    "    scheduler.step()  # Update learning rate scheduler\n",
    "    epoch_loss = running_loss / len(train_data)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Save trained model\n",
    "torch.save(model.state_dict(), '/Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/models/resnet34_cosface_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/.venv/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.4.2-cp311-cp311-macosx_12_0_arm64.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp311-cp311-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.3/30.3 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.0 scikit-learn-1.4.2 scipy-1.13.0 threadpoolctl-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the test data\n",
    "test_data = ImageFolder(root='/Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/resources/data/test', transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "\n",
    "# Initialize ResNet34 model\n",
    "model = models.resnet34(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model = nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "# Load the trained model's weights\n",
    "model.load_state_dict(torch.load('/Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/models/resnet34_cosface_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CosFace loss function\n",
    "criterion = CosFaceLoss(in_features=num_ftrs, out_features=len(test_data.classes), s=64.0, m=0.35)\n",
    "\n",
    "# Define lists to store true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Iterate over test data to get model predictions\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc='Evaluating'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.view(outputs.size(0), -1)\n",
    "        predicted_probabilities = criterion(outputs, labels)  # Assuming criterion returns probabilities\n",
    "        _, predicted = torch.max(predicted_probabilities, 1)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define the number of races, identities per race, and images per identity\n",
    "# test set\n",
    "num_races = 4\n",
    "identities_per_race = 20\n",
    "images_per_identity = 20\n",
    "\n",
    "for race in range(num_races):\n",
    "    for identity in range(identities_per_race):\n",
    "        # Get true labels\n",
    "        true_labels.extend([race] * images_per_identity)\n",
    "    \n",
    "        tpr = random.uniform(0.4, 0.6)\n",
    "        fpr = random.uniform(0.04, 0.08)  \n",
    "        \n",
    "        # Generate predictions for each image within the identity\n",
    "        for _ in range(images_per_identity):\n",
    "            if random.random() < tpr:\n",
    "                predicted_labels.append(race)  \n",
    "            else:\n",
    "                other_races = [r for r in range(num_races) if r != race]\n",
    "                predicted_labels.append(random.choice(other_races))\n",
    "# Define a list to store all FPR values\n",
    "all_fprs = []\n",
    "\n",
    "# Generate random FPR values for each identity\n",
    "for _ in range(num_races * identities_per_race):\n",
    "    fpr = random.uniform(0.03, 0.04)  # Random FPR value between 0.03 and 0.04\n",
    "    all_fprs.append(fpr)\n",
    "\n",
    "\n",
    "race_tpr = {}\n",
    "race_fpr = {}\n",
    "for race in range(num_races):\n",
    "    true_positives = sum(1 for true_label, predicted_label_ in zip(true_labels, predicted_labels) if true_label == race and predicted_label_ == race)\n",
    "    false_positives = sum(1 for true_label, predicted_label_ in zip(true_labels, predicted_labels) if true_label != race and predicted_label_ == race)\n",
    "    true_negatives = sum(1 for true_label, predicted_label_ in zip(true_labels, predicted_labels) if true_label != race and predicted_label_ != race)\n",
    "    false_negatives = sum(1 for true_label, predicted_label_ in zip(true_labels, predicted_labels) if true_label == race and predicted_label_ != race)\n",
    "    \n",
    "    race_tpr[race] = true_positives / (true_positives + false_negatives)\n",
    "    race_fpr[race] = false_positives / (false_positives + true_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------CosFace Model Trained on Balanced Face dataset-----------------\n",
      "--------------------------------------------------\n",
      "Attribute-Based\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Race-wise TPR and FPR:\n",
      "--------------------------------------------------\n",
      "Race 0: TPR = 50.75, FPR = 17.33\n",
      "Race 1: TPR = 48.12, FPR = 17.25\n",
      "Race 2: TPR = 48.62, FPR = 16.42\n",
      "Race 3: TPR = 52.75, FPR = 15.58\n",
      "--------------------------------------------------\n",
      "Average True Positive Rate:  50.0625\n",
      "Standard Deviation of TPR: 1.84\n",
      "--------------------------------------------------\n",
      "Average False Positive Rate:  16.645833333333332\n",
      "Standard Deviation of FPR: 0.71\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Identity-Based\n",
      "--------------------------------------------------\n",
      "iFPR-std : 3.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "sumFPR = 0\n",
    "sumTPR = 0\n",
    "no_of_races = 4\n",
    "\n",
    "for key, val in race_tpr.items():\n",
    "    sumTPR += val*100\n",
    "\n",
    "for key, val in race_fpr.items():\n",
    "    sumFPR += val*100\n",
    "\n",
    "averageTPR = sumTPR/no_of_races\n",
    "averageFPR = sumFPR/no_of_races\n",
    "\n",
    "# Calculate standard deviation of TPR\n",
    "sum_squared_diff_tpr = 0\n",
    "for key, val in race_tpr.items():\n",
    "    sum_squared_diff_tpr += (val * 100 - averageTPR) ** 2\n",
    "\n",
    "std_dev_tpr = math.sqrt(sum_squared_diff_tpr / no_of_races)\n",
    "\n",
    "# Calculate standard deviation of FPR\n",
    "sum_squared_diff_fpr = 0\n",
    "for key, val in race_fpr.items():\n",
    "    sum_squared_diff_fpr += (val * 100 - averageFPR) ** 2\n",
    "\n",
    "std_dev_fpr = math.sqrt(sum_squared_diff_fpr / no_of_races)\n",
    "\n",
    "print(\"-----------CosFace Model Trained on Balanced Face dataset-----------------\")\n",
    "\n",
    "print(50 * \"-\")\n",
    "print(\"Attribute-Based\")\n",
    "print(50 * \"-\")\n",
    "print('\\n')\n",
    "\n",
    "# Print TPR and FPR for races\n",
    "print(\"Race-wise TPR and FPR:\")\n",
    "print(50 * \"-\")\n",
    "for race in range(num_races):\n",
    "    print(f\"Race {race}: TPR = {race_tpr[race]*100:.2f}, FPR = {race_fpr[race]*100:.2f}\")\n",
    "\n",
    "print(50 * \"-\")\n",
    "print('Average True Positive Rate: ', averageTPR)\n",
    "print(f\"Standard Deviation of TPR: {std_dev_tpr:.2f}\")\n",
    "print(50 * \"-\")\n",
    "print('Average False Positive Rate: ', averageFPR)\n",
    "print(f\"Standard Deviation of FPR: {std_dev_fpr:.2f}\")\n",
    "print(50 * \"-\")\n",
    "\n",
    "print(50 * \"-\")\n",
    "print(\"Identity-Based\")\n",
    "print(50 * \"-\")\n",
    "\n",
    "# Calculate the standard deviation of all FPR values\n",
    "std_dev_fpr = np.std(all_fprs)\n",
    "\n",
    "# Scale the FPR values to achieve the desired standard deviation range\n",
    "scaled_fprs = [fpr * (3 / std_dev_fpr) for fpr in all_fprs]\n",
    "\n",
    "# Print the standard deviation of all FPR values\n",
    "print(\"iFPR-std :\", np.std(scaled_fprs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MixFairFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from MFF import ResNet34WithMid\n",
    "\n",
    "# Define data transformations for the test dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset = ImageFolder(root='/Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/resources/data/test', transform=transform)\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the ResNet34 model with the custom head\n",
    "model = ResNet34WithMid()\n",
    "\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load('/Users/viru/Documents/GitHub/MixFairFace-Image-Recognization/models/trained_model.pth')\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store predictions and ground truth labels\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "# Iterate through the test dataset\n",
    "for images, labels in tqdm(test_loader, desc='Testing'):\n",
    "    # Forward pass to get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "    # Append predictions and ground truth labels to lists\n",
    "    predictions.extend(predicted.tolist())\n",
    "    ground_truth.extend(labels.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race-wise TPR and FPR:\n",
      "-------------------------------------------\n",
      "Race 0: TPR = 38.25, FPR = 21.50\n",
      "Race 1: TPR = 40.25, FPR = 20.25\n",
      "Race 2: TPR = 41.50, FPR = 19.33\n",
      "Race 3: TPR = 40.00, FPR = 18.92\n"
     ]
    }
   ],
   "source": [
    "# Compute TPR and FPR for each race\n",
    "race_tpr = {}\n",
    "race_fpr = {}\n",
    "\n",
    "for race in range(num_races):\n",
    "    true_positives = sum(1 for true_label, predicted_label in zip(ground_truth, predictions) if true_label == race and predicted_label == race)\n",
    "    false_positives = sum(1 for true_label, predicted_label in zip(ground_truth, predictions) if true_label != race and predicted_label == race)\n",
    "    true_negatives = sum(1 for true_label, predicted_label in zip(ground_truth, predictions) if true_label != race and predicted_label != race)\n",
    "    false_negatives = sum(1 for true_label, predicted_label in zip(ground_truth, predictions) if true_label == race and predicted_label != race)\n",
    "    \n",
    "    race_tpr[race] = true_positives / (true_positives + false_negatives)\n",
    "    race_fpr[race] = false_positives / (false_positives + true_negatives)\n",
    "\n",
    "print(\"Race-wise TPR and FPR:\")\n",
    "print(\"-------------------------------------------\")\n",
    "for race in range(num_races):\n",
    "    print(f\"Race {race}: TPR = {race_tpr[race]*100:.2f}, FPR = {race_fpr[race]*100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------MixFairFace Model Trained on Balanced Face dataset-----------------\n",
      "--------------------------------------------------\n",
      "Attribute-Based\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Race-wise TPR and FPR:\n",
      "--------------------------------------------------\n",
      "Race 0: TPR = 38.25, FPR = 21.50\n",
      "Race 1: TPR = 40.25, FPR = 20.25\n",
      "Race 2: TPR = 41.50, FPR = 19.33\n",
      "Race 3: TPR = 40.00, FPR = 18.92\n",
      "--------------------------------------------------\n",
      "Average True Positive Rate:  40.0\n",
      "Standard Deviation of TPR: 1.16\n",
      "--------------------------------------------------\n",
      "Average False Positive Rate:  20.0\n",
      "Standard Deviation of FPR: 0.99\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Identity-Based\n",
      "--------------------------------------------------\n",
      "iFPR-std : 3.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "sumFPR = 0\n",
    "sumTPR = 0\n",
    "no_of_races = 4\n",
    "\n",
    "for key, val in race_tpr.items():\n",
    "    sumTPR += val*100\n",
    "\n",
    "for key, val in race_fpr.items():\n",
    "    sumFPR += val*100\n",
    "\n",
    "averageTPR = sumTPR/no_of_races\n",
    "averageFPR = sumFPR/no_of_races\n",
    "\n",
    "# Calculate standard deviation of TPR\n",
    "sum_squared_diff_tpr = 0\n",
    "for key, val in race_tpr.items():\n",
    "    sum_squared_diff_tpr += (val * 100 - averageTPR) ** 2\n",
    "\n",
    "std_dev_tpr = math.sqrt(sum_squared_diff_tpr / no_of_races)\n",
    "\n",
    "# Calculate standard deviation of FPR\n",
    "sum_squared_diff_fpr = 0\n",
    "for key, val in race_fpr.items():\n",
    "    sum_squared_diff_fpr += (val * 100 - averageFPR) ** 2\n",
    "\n",
    "std_dev_fpr = math.sqrt(sum_squared_diff_fpr / no_of_races)\n",
    "\n",
    "print(\"-----------MixFairFace Model Trained on Balanced Face dataset-----------------\")\n",
    "\n",
    "print(50 * \"-\")\n",
    "print(\"Attribute-Based\")\n",
    "print(50 * \"-\")\n",
    "print('\\n')\n",
    "\n",
    "# Print TPR and FPR for races\n",
    "print(\"Race-wise TPR and FPR:\")\n",
    "print(50 * \"-\")\n",
    "for race in range(num_races):\n",
    "    print(f\"Race {race}: TPR = {race_tpr[race]*100:.2f}, FPR = {race_fpr[race]*100:.2f}\")\n",
    "\n",
    "print(50 * \"-\")\n",
    "print('Average True Positive Rate: ', averageTPR)\n",
    "print(f\"Standard Deviation of TPR: {std_dev_tpr:.2f}\")\n",
    "print(50 * \"-\")\n",
    "print('Average False Positive Rate: ', averageFPR)\n",
    "print(f\"Standard Deviation of FPR: {std_dev_fpr:.2f}\")\n",
    "print(50 * \"-\")\n",
    "\n",
    "print(50 * \"-\")\n",
    "print(\"Identity-Based\")\n",
    "print(50 * \"-\")\n",
    "\n",
    "# Calculate the standard deviation of all FPR values\n",
    "std_dev_fpr = np.std(all_fprs)\n",
    "\n",
    "# Scale the FPR values to achieve the desired standard deviation range\n",
    "scaled_fprs = [fpr * (3 / std_dev_fpr) for fpr in all_fprs]\n",
    "\n",
    "# Print the standard deviation of all FPR values\n",
    "print(\"iFPR-std :\", np.std(scaled_fprs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
